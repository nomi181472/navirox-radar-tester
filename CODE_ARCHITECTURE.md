# Code Architecture Overview

## Project Structure
This is a **NaviUI Autonomous Navigation System** - a PyQt6-based maritime radar and object detection dashboard that fuses radar data with computer vision (YOLO) detections.

---

## ğŸ”— File Connections & Data Flow

### 1. **Application Entry Point**
```
main.py
  â””â”€> Initializes QApplication
  â””â”€> Creates MainWindow from naviui/app.py
  â””â”€> Applies dark theme stylesheet
```

### 2. **Main UI Architecture** (`naviui/`)

**naviui/app.py (MainWindow)**
- Creates 3-panel layout: `LeftPanel | CenterPanel | RightPanel`
- Connects radar control signals between left panel and center panel
- Central orchestrator of the UI

```
MainWindow
  â”œâ”€> LeftPanel (naviui/panels/left_panel.py)
  â”‚    â”œâ”€> CameraCell widgets (4 cameras: FWD, AFT, PORT, STBD)
  â”‚    â”œâ”€> Radar control sliders (zoom, height, range, beam angle, etc.)
  â”‚    â””â”€> HeatmapRow widgets for sensor visualization
  â”‚
  â”œâ”€> CenterPanel (naviui/panels/center_panel.py) â­ CORE FUSION LOGIC
  â”‚    â”œâ”€> TacticalMapScene (tactical_map.py) - Radar visualization
  â”‚    â”œâ”€> FusionManager (services/managers/fusion_manager.py) - Data fusion
  â”‚    â”œâ”€> InferenceService (services/inferenced_services/) - YOLO detections
  â”‚    â””â”€> PIPWindow (widgets/pip_window.py) - Detail overlay on click
  â”‚
  â””â”€> RightPanel (naviui/panels/right_panel.py)
       â”œâ”€> System status display
       â””â”€> Live console logs with timestamps
```

---

## 3. **Data Fusion Pipeline** (The Heart of the System)

### **CenterPanel** orchestrates the fusion:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CenterPanel (center_panel.py)          â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ TacticalMapScene â”‚â”€â”€â”€>â”‚  Radar Detectionsâ”‚  â”‚
â”‚  â”‚ (tactical_map.py)â”‚    â”‚  {rtrack_id,     â”‚  â”‚
â”‚  â”‚                  â”‚    â”‚   camera_id,     â”‚  â”‚
â”‚  â”‚ - Generates radarâ”‚    â”‚   angle, dist}   â”‚  â”‚
â”‚  â”‚   detections     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ - Displays on    â”‚              â”‚           â”‚
â”‚  â”‚   polar grid     â”‚              â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚           â”‚
â”‚                                    â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚           â”‚
â”‚  â”‚ InferenceService â”‚              â”‚           â”‚
â”‚  â”‚ (inference_      â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  service.py)     â”‚â”€â”€â”€>â”‚ FusionManager    â”‚  â”‚
â”‚  â”‚                  â”‚    â”‚ (managers/       â”‚  â”‚
â”‚  â”‚ - Dummy YOLO     â”‚    â”‚  fusion_manager  â”‚  â”‚
â”‚  â”‚   detections     â”‚    â”‚  .py)            â”‚  â”‚
â”‚  â”‚ - Runs every 3s  â”‚    â”‚                  â”‚  â”‚
â”‚  â”‚ - Provides       â”‚    â”‚ MATCHES by:      â”‚  â”‚
â”‚  â”‚   {track_id,     â”‚    â”‚ 1. camera_id     â”‚  â”‚
â”‚  â”‚    camera_id,    â”‚    â”‚ 2. timestamp     â”‚  â”‚
â”‚  â”‚    bbox, class}  â”‚    â”‚ 3. angle         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚           â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                          â”‚ Fused Detection  â”‚  â”‚
â”‚                          â”‚ {rtrack_id,      â”‚  â”‚
â”‚                          â”‚  track_id,       â”‚  â”‚
â”‚                          â”‚  camera_id,      â”‚  â”‚
â”‚                          â”‚  angle, distance,â”‚  â”‚
â”‚                          â”‚  bbox, class,    â”‚  â”‚
â”‚                          â”‚  confidence}     â”‚  â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    â”‚           â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                          â”‚ Update Tactical  â”‚  â”‚
â”‚                          â”‚ Map with Labels  â”‚  â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Connection Points:**
1. `TacticalMapScene.radar_detections_updated` signal â†’ `FusionManager.update_radar_detections()`
2. `InferenceService.run_inference()` called by timer â†’ `FusionManager.update_yolo_detections()`
3. `FusionManager.get_fused_detections()` â†’ Updates `TacticalMapScene` markers with class labels

---

## 4. **Model Pipeline** (`services/model/`)

```
ModelPipeline (model_pipeline.py)
  â””â”€> Orchestrates cascade of ML models
  â””â”€> Uses PipeStructure (pipe_structure.py) to define:
      - Model execution order
      - Dependencies between stages
      - Region definitions (polygon/bbox/line)

Example pipeline stages:
  Stage 1: general_object_detection_detector.py â†’ Object Detection (YOLO)
  Stage 1: general_object_detection_tracker.py â†’ Object Tracking
  Stage 2: depth_estimation_stage2.py â†’ Depth Estimation
  Stage 3: raft_direction_estimation_stage3.py â†’ Direction Estimation
```

**Key Files:**
- `services/model/cfgs/ibase_stage.py` - Base interface for pipeline stages
- `services/common/models/pipe_structure.py` - Data models for pipeline configuration

---

## 5. **Visualization Services** (`services/visualization/`)

```
MasterAnnotationRenderer (master_annotation_renderer.py)
  â”œâ”€> Base class for all renderers
  â”œâ”€> Adds timestamp overlay
  â””â”€> Uses ColorManager for consistent color schemes

â”œâ”€> DetectionAnnotationRenderer - Draws bounding boxes
â”œâ”€> DirectionAnnotationRenderer - Draws direction arrows
â””â”€> IAnnotationRenderer - Interface contract
```

**Connection:** Used by inference services to annotate video frames with detections

---

## 6. **Manager Components** (`services/managers/`)

1. **FusionManager** (`fusion_manager.py`) â­
   - Matches radar detections with YOLO detections
   - Criteria: camera_id, timestamp (Â±6s), angle (Â±45Â°)
   - Outputs fused detection objects

2. **ColorManager** (`color_manager.py`)
   - Manages consistent color schemes for object classes

3. **TrackerManager** / **TrackerFactory** (`tracker_manager.py`, `tracker_factory.py`)
   - Creates and manages object trackers (YOLO-based)
   - Supports different tracker types: BoT-SORT, ByteTrack, etc.

4. **ModelStrategyManager** (`model_strategy_manager.py`)
   - Selects appropriate model strategy based on config

---

## 7. **Data Loaders** (`services/loaders/`)

```
IDataLoader (idata_loader.py) - Interface
  â””â”€> DetectionDataLoader (detection_data_loader.py)
      - Loads and parses YOLO detection results
      - Converts to internal detection format
```

---

## 8. **Widget Components** (`naviui/widgets/`)

- **CameraCell** - Individual camera preview with status indicators
- **HeatmapRow** - Sensor heatmap visualization row
- **PIPWindow** - Picture-in-picture detail overlay (shows on radar marker click)
- **ToggleSwitch** - Custom toggle switch UI component

---

## ğŸ”„ Complete Data Flow Example

**Scenario:** Object detected in camera view

```
1. TacticalMapScene generates radar detection
   â””â”€> {rtrack_id: 1, camera_id: 2, angle: 45Â°, distance: 200m}
   â””â”€> Emits radar_detections_updated signal

2. InferenceService.run_inference() runs (timer-based, every 3s)
   â””â”€> Generates YOLO detection
   â””â”€> {track_id: 5, camera_id: 2, bbox: [100,200,300,400], 
        class: "vessel-ship", confidence: 0.89}

3. FusionManager receives both streams
   â””â”€> Matches by camera_id=2, similar angle (bbox center â†’ angle)
   â””â”€> Creates fused detection:
       {rtrack_id: 1, track_id: 5, camera_id: 2, 
        angle: 45Â°, distance: 200m, bbox: [...],
        class: "vessel-ship", confidence: 0.89}

4. CenterPanel receives fused detection
   â””â”€> Updates TacticalMapScene marker with class label
   â””â”€> Marker now shows "vessel-ship" instead of generic radar blip

5. User clicks marker on TacticalMapScene
   â””â”€> Emits obstacle_clicked signal
   â””â”€> CenterPanel shows PIPWindow with detailed info
```

---

## ğŸ¨ UI Theme & Styling

- **styles.py** - Contains DARK_STYLESHEET with maritime-themed colors
- **Constants:**
  - `constants/color.py` - Color definitions
  - `constants/detections_constant.py` - Detection-related constants

---

## ğŸ§ª Testing Structure

```
tests/ - Unit and integration tests
services/model/cfgs/stage1/test/ - Stage 1 model tests
services/model/cfgs/stage2/test/ - Stage 2 model tests
```

---

## ğŸ“¦ Key Dependencies (from requirements.txt)

- **PyQt6** - UI framework
- **torch** - Deep learning models
- **ultralytics** - YOLO models
- **opencv-python** - Image processing
- **numpy** - Numerical computations

---

## ğŸ¯ Critical Integration Points

1. **Radar â†’ Fusion:** `TacticalMapScene.radar_detections_updated` signal
2. **YOLO â†’ Fusion:** `InferenceService.run_inference()` â†’ `FusionManager.update_yolo_detections()`
3. **Fusion â†’ UI:** `FusionManager.get_fused_detections()` â†’ `TacticalMapScene` marker updates
4. **UI Controls â†’ Radar:** `LeftPanel` slider signals â†’ `TacticalMapScene.update_radar_parameters()`
5. **User Interaction:** `TacticalMapScene.obstacle_clicked` â†’ `PIPWindow.show()`

---

## ğŸ“ Notes for Development

- Currently using **dummy data** in `InferenceService` and `FusionManager`
- Real YOLO model integration: Replace `InferenceService.run_inference()` body
- Real radar feed: Replace `TacticalMapScene._generate_random_obstacle()` with actual radar data stream
- Fusion thresholds tunable in `fusion_manager.py`: `MAX_TIME_DELTA_S`, `MAX_ANGLE_DELTA_DEG`
